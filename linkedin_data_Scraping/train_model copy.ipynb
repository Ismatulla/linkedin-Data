{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('https://raw.githubusercontent.com/fayyoz24/Bots_using_selenium/main/model_crystal/without%20certifications%20linkedin%20profiles.csv')\n",
    "cols=['position 1', 'position 2', 'field of studies 1','experince 1', 'experince 2', 'field of studies 2',\n",
    "       'degree 1', 'degree 2', 'industry', 'skills', 'influencer', 'country']\n",
    "\n",
    "for col in cols:\n",
    "  data[col] = data[col].fillna(\"Unknown\")\n",
    "# Convert non-string values to strings in the feature columns\n",
    "text_features = data[['position 1', 'position 2', \"experince 1\",\"experince 2\", \n",
    "                      'field of studies 1', 'field of studies 2', \n",
    "                      'degree 1', 'degree 2', 'industry', 'skills',\n",
    "                      'influencer', 'country', 'summary']].copy()\n",
    "\n",
    "# Handle non-string values in each column\n",
    "for column in text_features.columns:\n",
    "    text_features[column] = text_features[column].astype(str)\n",
    "\n",
    "# Combine all text features into a single string column\n",
    "text_data = text_features.apply(lambda x: ' '.join(x), axis=1).tolist()\n",
    "labels = data['characters'].tolist()\n",
    "\n",
    "# Convert labels to integers\n",
    "label_mapping = {label: idx for idx, label in enumerate(set(labels))}\n",
    "y = np.array([label_mapping[label] for label in labels])\n",
    "\n",
    "# Update label mapping to start from 0\n",
    "label_mapping = {label: idx for label, idx in label_mapping.items()}\n",
    "num_classes = len(label_mapping)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = len(word_index) + 1\n",
    "sequences = tokenizer.texts_to_sequences(text_data)\n",
    "\n",
    "# Pad sequences to have consistent length\n",
    "max_sequence_length = max(len(seq) for seq in sequences)\n",
    "print(max_sequence_length)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# Convert the data to NumPy arrays\n",
    "X_text = np.array(padded_sequences)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_text, X_test_text, y_train, y_test = train_test_split(\n",
    "    X_text, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Textual input branch\n",
    "text_input = Input(shape=(max_sequence_length,))\n",
    "embedding_layer = Embedding(vocab_size, 100, input_length=max_sequence_length)(text_input)\n",
    "lstm_layer = LSTM(100)(embedding_layer)\n",
    "output_layer = Dense(num_classes, activation='softmax')(lstm_layer)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=text_input, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_text, y_train, validation_data=(X_test_text, y_test),\n",
    "          epochs=50, batch_size=32)\n",
    "\n",
    "# Save the model\n",
    "model.save('model2_test_size=0.1.h5')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
