{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\AppData\\Local\\Temp\\ipykernel_6484\\3966096366.py:10: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(options=options,executable_path='C:/Users/dell/OneDrive/Desktop/chromedriver-win64/chromedriver.exe')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am done ---> Karaganda\n",
      "I am done ---> Aktobe\n",
      "I am done ---> Taraz\n",
      "I am done ---> Pavlodar\n"
     ]
    }
   ],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "options = Options()\n",
    "options.add_argument(\"user-data-dir=C:/Users/dell/AppData/Local/Google/Chrome/User Data/Profile 60\")\n",
    "                                                        #C:\\Users\\fayyo\\Downloads\\chromedriver-win32.zip\\chromedriver-win32\n",
    "driver = webdriver.Chrome(options=options,executable_path='C:/Users/dell/OneDrive/Desktop/chromedriver-win64/chromedriver.exe')\n",
    "# country names\n",
    "list_items = [\n",
    "    \"Karaganda\",\n",
    "    \"Aktobe\",\n",
    "    \"Taraz\",\n",
    "    \"Pavlodar\",\n",
    "    \"Ust-Kamenogorsk\",\n",
    "    \"Semey\",\n",
    "    \"Kostanay\",\n",
    "    \"Atyrau\",\n",
    "    \"Petropavl\",\n",
    "    \"Oral\",\n",
    "    \"Temirtau\",\n",
    "    \"Aktau\",\n",
    "    \"Kyzylorda\",\n",
    "    \"Zhezkazgan\",\n",
    "    \"Kokshetau\",\n",
    "    \"Taldykorgan\",\n",
    "    \"Ekibastuz\",\n",
    "    \"Rudny\",\n",
    "    \"Aksu\",\n",
    "    \"Turkestan\",\n",
    "    \"Balqash\",\n",
    "    \"Kentau\",\n",
    "    \"Ridder\",\n",
    "    \"Kapchagay\",\n",
    "    \"Saryaghash\",\n",
    "    \"Shakhtinsk\",\n",
    "    \"Stepnogorsk\",\n",
    "    \"Zhanaozen\",\n",
    "    \"Zaysan\",\n",
    "    \"Arys\",\n",
    "    \"Lisakovsk\",\n",
    "    \"Atbasar\",\n",
    "    \"Shu\",\n",
    "    \"Khromtau\",\n",
    "    \"Makinsk\",\n",
    "    \"Tobol\",\n",
    "    \"Aksay\",\n",
    "    \"Zhangatas\",\n",
    "    \"Ayagoz\",\n",
    "    \"Esik\",\n",
    "    \"Shardara\",\n",
    "    \"Dzhezkazgan\",\n",
    "    \"Zholymbet\",\n",
    "    \"Zharkent\",\n",
    "    \"Derzhavinsk\",\n",
    "    \"Shchuchinsk\",\n",
    "    \"Kurchatov\",\n",
    "    \"Zyryanovsk\",\n",
    "    \"Arkalyk\",\n",
    "    \"Sarkand\",\n",
    "    \"Rudnyy\",\n",
    "    \"Talgar\",\n",
    "    \"Kandagach\",\n",
    "    \"Kapshagay\",\n",
    "    \"Leninogorsk\",\n",
    "    \"Lenger\",\n",
    "    \"Zhanaozen\",\n",
    "    \"Shieli\",\n",
    "    \"Zharkent\",\n",
    "    \"Sarykemer\",\n",
    "    \"Shetpe\",\n",
    "    \"Urzhar\",\n",
    "    \"Ushtobe\",\n",
    "    \"Zhangaqorghan\",\n",
    "    \"Turar Ryskulov\",\n",
    "    \"Shalkar\",\n",
    "    \"Komsomolets\",\n",
    "    \"Aral\",\n",
    "    \"Makhambet\",\n",
    "    \"Aqsu\",\n",
    "    \"Zhangatas\",\n",
    "    \"Serebryansk\",\n",
    "    \"Kachiry\",\n",
    "    \"Yereymentau\",\n",
    "    \"Emba\",\n",
    "    \"Glubokoe\",\n",
    "    \"Tekeli\",\n",
    "    \"Bestobe\",\n",
    "    \"Birlik\",\n",
    "    \"Saran\",\n",
    "    \"Chu\",\n",
    "    \"Merei\",\n",
    "    \"Zhetisay\",\n",
    "    \"Lugovoy\",\n",
    "    \"Khromtau\",\n",
    "    \"Georgievka\",\n",
    "    \"Zhanga-Tas\",\n",
    "    \"Bektemir\",\n",
    "    \"Karasu\",\n",
    "    \"Kurort-Borovoye\",\n",
    "    \"Oktyabrskoye\",\n",
    "    \"Shakhan\",\n",
    "    \"Kyzyltu\",\n",
    "    \"Mendykaragay\",\n",
    "    \"Baiterek\",\n",
    "    \"Sholakkorgan\",\n",
    "    \"Birzhan Sal\",\n",
    "    \"Oskemen\",\n",
    "    \"Otar\",\n",
    "    \"Shemonaikha\",\n",
    "    \"Priozersk\",\n",
    "    \"Kulan\",\n",
    "    \"Ridder\",\n",
    "    \"Sandyktau\",\n",
    "    \"Zhetiqara\",\n",
    "    \"Kazalinsk\",\n",
    "    \"Ayakoz\",\n",
    "    \"Tasboget\",\n",
    "    \"Ridder\",\n",
    "    \"Zhezqazghan\",\n",
    "    \"Chapaev\",\n",
    "    \"Glubokoye\",\n",
    "    \"Esil\",\n",
    "    \"Ushtobe\",\n",
    "    \"Georgiyevka\",\n",
    "    \"Kokshetaw\",\n",
    "    \"Karazhal\",\n",
    "    \"Bulaevo\",\n",
    "    \"Aksu\",\n",
    "    \"Shchuchinsk\",\n",
    "    \"Saryshaghan\",\n",
    "    \"Derzhavinsk\",\n",
    "    \"Talovyy\",\n",
    "    \"Qulsary\",\n",
    "    \"Tasboget\",\n",
    "    \"Shar\",\n",
    "    \"Khovd\",\n",
    "    \"Esil\",\n",
    "    \"Glubokoye\",\n",
    "    \"Zyryanovsk\",\n",
    "    \"Lugovoy\",\n",
    "    \"Serebryansk\",\n",
    "    \"Tasboget\",\n",
    "    \"Arqalyq\",\n",
    "    \"Zaisan\",\n",
    "    \"Qarqaraly\",\n",
    "    \"Shalqar\",\n",
    "    \"Tobyl\",\n",
    "    \"Tasboget\",\n",
    "    \"Lisakovsk\",\n",
    "    \"Glubokoye\",\n",
    "    \"Qapshagay\",\n",
    "    \"Shakhtinsk\",\n",
    "    \"Tobyl\",\n",
    "    \"Qapshagay\",\n",
    "    \"Aqtau\",\n",
    "    \"Qyzylorda\",\n",
    "    \"Shalqar\",\n",
    "    \"Tobyl\",\n",
    "    \"Shar\",\n",
    "    \"Zyryanovsk\",\n",
    "    \"Qapshagay\",\n",
    "    \"Tasboget\",\n",
    "    \"Tobyl\",\n",
    "    \"Qapshagay\",\n",
    "    \"Aqtau\",\n",
    "    \"Qyzylorda\",\n",
    "    \"Shalqar\",\n",
    "    \"Tobyl\",\n",
    "    \"Shar\",\n",
    "    \"Zyryanovsk\",\n",
    "    \"Qapshagay\",\n",
    "    \"Tasboget\",\n",
    "    \"Tobyl\",\n",
    "    \"Qapshagay\",\n",
    "    \"Aqtau\",\n",
    "    \"Qyzylorda\",\n",
    "    \"Shalqar\",\n",
    "    \"Tobyl\",\n",
    "    \"Shar\",\n",
    "    \"Zyryanovsk\",\n",
    "    \"Qapshagay\",\n",
    "    \"Tasboget\",\n",
    "    \"Tobyl\",\n",
    "    \"Qapshagay\",\n",
    "    \"Aqtau\",\n",
    "    \"Qyzylorda\",\n",
    "    \"Shalqar\",\n",
    "    \"Tobyl\",\n",
    "    \"Shar\",\n",
    "    \"Zyryanovsk\",\n",
    "    \"Qapshagay\",\n",
    "    \"Tasboget\",\n",
    "    \"Tobyl\",\n",
    "    \"Qapshagay\",\n",
    "    \"Aqtau\",\n",
    "    \"Qyzylorda\",\n",
    "    \"Shalqar\",\n",
    "    \"Tobyl\",\n",
    "    \"Shar\",\n",
    "    \"Zyryanovsk\",\n",
    "    \"Qapshagay\",\n",
    "    \"Tasboget\",\n",
    "    \"Tobyl\",\n",
    "    \"Qapshagay\",\n",
    "    \"Aqtau\",\n",
    "    \"Qyzylorda\",\n",
    "    \"Shalqar\",\n",
    "    \"Tobyl\",\n",
    "    \"Shar\",\n",
    "    \"Zyryanovsk\",\n",
    "    \"Qapshagay\",\n",
    "    \"Tasboget\",\n",
    "    \"Tobyl\",\n",
    "    \"Qapshagay\",\n",
    "    \"Aqtau\",\n",
    "    \"Qyzylorda\",\n",
    "    \"Shalqar\",\n",
    "    \"Tobyl\",\n",
    "    \"Shar\",\n",
    "    \"Zyryanovsk\",\n",
    "    \"Qapshagay\",\n",
    "    \"Tasboget\",\n",
    "    \"Tobyl\",\n",
    "    \"Qapshagay\",\n",
    "    \"Aqtau\",\n",
    "    \"Qyzylorda\",\n",
    "    \"Shalqar\",\n",
    "    \"Tobyl\",\n",
    "    \"Shar\",\n",
    "    \"Zyryanovsk\",\n",
    "    \"Qapshagay\",\n",
    "    \"Tasboget\",\n",
    "    \"Tobyl\",\n",
    "    \"Qapshagay\"\n",
    "]\n",
    "\n",
    "\n",
    "for item  in list_items[:]:\n",
    "    links = []\n",
    "    for study in ['master', 'bachelor']:\n",
    "        driver.get(f'https://www.google.com/search?q=site:nl.linkedin.com/in/+AND+%22{item}+AND+%22{study}')\n",
    "        time.sleep(10) # to make slower \n",
    "        # n is the number of pages\n",
    "        n=30\n",
    "        while n > 0:\n",
    "            time.sleep(5)\n",
    "            for i in range(1, 11): # google uses paginator, every page has 10 urls\n",
    "                time.sleep(6)\n",
    "                        #//*[@id=\"rso\"]/div[9]/div/div/div/div[1]/div/div/a\n",
    "                try:    #/html/body/div[6]/div/div[13]/div/div[2]/div[2]/div/div/div[1]/div/div/div[1]/div/div/a\n",
    "                        #/html/body/div[6]/div/div[13]/div/div[2]/div[2]/div/div/div[4]/div/div/div[1]/div/div/a\n",
    "                        #/html/body/div[6]/div/div[13]/div/div[2]/div[2]/div/div/div[9]/div/div/div/div[1]/div/div/a\n",
    "                    elems = driver.find_elements(By.XPATH, '/html/body/div[6]/div/div[12]/div/div[2]/div[2]/div/div/div['+str(i)+']/div/div/div[1]/div/div/a')\n",
    "                    for elem in elems:                     #/html/body/div[6]/div/div[12]/div/div[2]/div[2]/div/div/div[3]/div/div/div[1]/div/div/a\n",
    "                                                           #/html/body/div[6]/div/div[12]/div/div[2]/div[2]/div/div/div[2]/div/div/div[1]/div/div/a\n",
    "                        clean_url = elem.get_attribute(\"href\") # extracting url \n",
    "                        base_url = \"linkedin.com/in/\"\n",
    "                        if clean_url.find(base_url) != -1 and '%' not in clean_url: # sometimes google gives no Ln urls, so clean it\n",
    "                            links.append(clean_url)\n",
    "                            # print(f\"url is --->{clean_url}\")\n",
    "                except Exception as e:\n",
    "                    print(\"problem with ELEMS\")\n",
    "                    pass\n",
    "            try:                                            #//*[@id=\"pnnext\"]/span[2]\n",
    "                next_button = driver.find_element(By.XPATH, '//*[@id=\"pnnext\"]') # clicking next button \n",
    "                next_button.click()\n",
    "            except Exception as e:\n",
    "                driver.get(f'https://www.google.com/search?q=site:nl.linkedin.com/in/+AND+%22{item}+AND+%22{study}')\n",
    "                # print(\"\")\n",
    "            # print(f'{n} pages left!')\n",
    "            n -= 1\n",
    "    df = pd.DataFrame({\n",
    "        \"links\":links\n",
    "    })\n",
    "    df1=pd.read_csv('datas/Ismatulla_links/data_Ismatulla3.csv')\n",
    "    df_sum=pd.concat([df1, df], axis=0, ignore_index=True)\n",
    "    df_sum = df_sum.drop_duplicates()\n",
    "    df_sum.to_csv(f'datas/Ismatulla_links/data_Ismatulla3.csv', index=False)\n",
    "    print(f'I am done ---> {item}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am done ---> Dhaka, Bangladesh\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"links\":links\n",
    "})\n",
    "df1=pd.read_csv('datas/Fayyoz_links/data_Fayyoz.csv')\n",
    "df_sum=pd.concat([df1, df], axis=0, ignore_index=True)\n",
    "df_sum = df_sum.drop_duplicates()\n",
    "df_sum.to_csv(f'datas/Fayyoz_links/data_Fayyoz.csv', index=False)\n",
    "print(f'I am done ---> {item}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am done ---> Shanghai, China\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"links\":links\n",
    "})\n",
    "df1=pd.read_csv('datas/Fayyoz_links/data_Fayyoz.csv')\n",
    "# df = df.drop_duplicates()\n",
    "df_sum=pd.concat([df1, df], axis=0, ignore_index=True)\n",
    "df_sum = df_sum.drop_duplicates()\n",
    "df_sum.to_csv(f'datas/Fayyoz_links/data_Fayyoz.csv', index=False)\n",
    "print(f'I am done ---> {item}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=592"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am done ---> 599\n",
      "if there is a problem, start with 600\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({\n",
    "    \"links\":links\n",
    "})\n",
    "df = df.drop_duplicates()\n",
    "df.to_csv(f'datas/linkedin_links_29_06/data{str(j)}.csv', index=False)\n",
    "print(f'I am done ---> {str(j)}')\n",
    "print(f'if there is a problem, start with {str(j+1)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "chrome_driver_path = Service(\n",
    "    \"chromedriver.exe\")\n",
    "driver = webdriver.Chrome(service=chrome_driver_path)\n",
    "\n",
    "# options = Options()\n",
    "# options.add_argument(\"user-data-dir=C:\\\\Users\\\\Username\\\\AppData\\\\Local\\\\Google\\\\Chrome\\\\User Data\")\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "# 'Mathematics and Bachelor words are used as a default, it is changeble\n",
    "driver.get('https://www.google.com/search?q=site:nl.linkedin.com/in/+AND+%22Computational Social Science%22+AND+%22Bachelor%27s&sxsrf=ALiCzsbOTqrA98wDQf3mtEB03kA_O7eCbQ:1668686082134&ei=AiF2Y4vwB-3JrgS9gpd4&start=50&sa=N&ved=2ahUKEwiL-aqJlLX7AhXtpIsKHT3BBQ84KBDy0wN6BAgBEA0&biw=920&bih=625&dpr=1')\n",
    "time.sleep(10) # to make slower \n",
    "\n",
    " # n is the number of pages\n",
    "links = [] # save links here\n",
    "n=6\n",
    "while n > 0:\n",
    "    time.sleep(5)\n",
    "    for i in range(1, 11): # google uses paginator, every page has 10 urls\n",
    "        time.sleep(6)\n",
    "        try:\n",
    "            elems = driver.find_elements(By.XPATH, '//*[@id=\"rso\"]/div['+str(i)+']/div/div/div[1]/div/a')\n",
    "            for elem in elems:\n",
    "                \n",
    "                clean_url = elem.get_attribute(\"href\") # extracting url \n",
    "                base_url = \"linkedin.com/in/\"\n",
    "                if clean_url.find(base_url) != -1 and '%' not in clean_url: # sometimes google gives no Ln urls, so clean it\n",
    "                    links.append(clean_url)\n",
    "                    print(f\"url is --->{clean_url}\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass\n",
    "    try:\n",
    "        next_button = driver.find_element(By.XPATH, '//*[@id=\"pnnext\"]') # clicking next button \n",
    "        next_button.click()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    print(f'{n} pages left!')\n",
    "    n -= 1\n",
    "df = pd.DataFrame({\n",
    "    \"links\":links\n",
    "})\n",
    "df.to_csv('datas/linkedin_aaccount_links/Filosofie.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e53cf64bf1c27840c77398a8ccfc4c3ccd90183c2c0ca3f1ba55da13fcc257d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
