{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import json\n",
    "\n",
    "time.sleep(15)\n",
    "for page  in range(1, 10):\n",
    "    site=\"https://magnet.me/nl-NL/banen?jobFunctions=accounting&jobFunctions=administrative&jobFunctions=finance&jobFunctions=fiscal&page=\"+str(page)\n",
    "    driver = webdriver.Chrome(executable_path='C:/Users/fayyo/Downloads/chromedriver.exe')\n",
    "    driver.get(site)\n",
    "    dict_list=[]\n",
    "    for li_num in range(1, 21):\n",
    "        dict_={}\n",
    "        time.sleep(5)\n",
    "        li=driver.find_element(By.XPATH, '/html/body/div/div/div/div[4]/div/div[1]/div[2]/div/div[3]/div/div/div[1]/div/ol/li['+str(li_num)+']')\n",
    "        li.click()\n",
    "        time.sleep(10)\n",
    "\n",
    "        src = driver.page_source\n",
    "        soup = BeautifulSoup(src, 'lxml')\n",
    "        try:\n",
    "            job_title=soup.find(\"h1\", {\"data-monitoring\":\"opportunityName\"})\n",
    "            dict_['job_title']=job_title.text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            experience=soup.find(\"div\", {\"data-testid\":\"experience\"})\n",
    "            dict_['experience']=experience.text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            deadline=soup.find(\"div\", {\"data-testid\":\"deadline\"})\n",
    "            dict_['deadline']=deadline.text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            languages=soup.find(\"div\", {\"data-testid\":\"languages\"})\n",
    "            dict_['languages']=languages.text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            degree=soup.find(\"div\", {\"data-testid\":\"degree\"})\n",
    "            dict_['degree']=degree.text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            emp_type=soup.find(\"div\", {\"data-testid\":\"employmentType\"})\n",
    "            dict_['Employment Type']=emp_type.text\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            job_functions=soup.find(\"div\", {\"data-testid\":\"jobFunctions\"})\n",
    "            dict_['job_functions']=job_functions.text\n",
    "        except:\n",
    "            pass\n",
    "        advert_element=driver.find_element(By.XPATH, '/html/body/div[1]/div/div/div[4]/div/div[1]/div/div/div[3]/div/div/div[2]/div/div/div[3]')\n",
    "\n",
    "        if advert_element.text == \"Je carrière begint op Magnet.me\\nMaak een profiel aan en ontvang slimme aanbevelingen op basis van je gelikete vacatures.\\nProfiel aanmaken\":\n",
    "            # Find the next div sibling element\n",
    "            next_div_element = advert_element.find_element(By.XPATH, './following-sibling::div[1]')\n",
    "\n",
    "            next_div_text = next_div_element.text\n",
    "            # print(\"Next Div Text:\", next_div_text)\n",
    "            dict_['Job Description']=next_div_text\n",
    "\n",
    "        # Use the XPath expression to locate the first element by class name\n",
    "        first_element = driver.find_element(By.XPATH, \"/html/body/div[1]/div/div/div[4]/div/div[1]/div[2]/div/div[3]/div/div/div[2]/div/div/div[2]/div/div[3]\")\n",
    "\n",
    "        # Find the next sibling element (regardless of its class name)\n",
    "        next_sibling_element = first_element.find_element(By.XPATH, \"following-sibling::*\")\n",
    "\n",
    "        # Now you can interact with the next sibling element as needed\n",
    "        try:\n",
    "            next_sibling_text = next_sibling_element.text\n",
    "            dict_['salary']=next_sibling_text.split('Salaris')[1].replace('\\n', '').replace('€', '')\n",
    "        except:\n",
    "            pass\n",
    "        dict_list.append(dict_)\n",
    "        driver.back()\n",
    "        # print(\"Next Sibling Text:\", next_sibling_text)\n",
    "    \n",
    "    json_string = json.dumps(dict_list)\n",
    "\n",
    "    with open(f\"data{page}.json\", \"w\") as json_file:\n",
    "        json.dump(dict_list, json_file, indent=4)\n",
    "    print(f'page number {page} is done!')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
